{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Emotion Recognition Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports/Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Reproducability\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\") # to clean up output cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to train/test data\n",
    "train_path = r'./images/train/'\n",
    "test_path = r'./images/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: Show first image in happy dataset\n",
    "happy_img_path = train_path + 'happy/' + os.listdir(train_path+'happy/')[0]\n",
    "happy_img = plt.imread(happy_img_path)\n",
    "plt.imshow(happy_img)\n",
    "print(happy_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all images have same shape\n",
    "image_shape = (48, 48)\n",
    "\n",
    "# Image generator\n",
    "img_generate = ImageDataGenerator(rotation_range=20, # rotate the image 20 degrees\n",
    "                               width_shift_range=0.10, # Shift the image width by a max of 5%\n",
    "                               height_shift_range=0.10, # Shift the image height by a max of 5%\n",
    "                               rescale=1/255, # Rescale the image by normalzing it.\n",
    "                               horizontal_flip=True, # Allo horizontal flipping\n",
    "                               fill_mode='nearest' # Fill in missing pixels with the nearest filled value\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1f05d4bdb80>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_generate.flow_from_directory(train_path)\n",
    "img_generate.flow_from_directory(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(2,2),input_shape=image_shape, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Dropouts help reduce overfitting by randomly turning neurons off during training.\n",
    "# Here we say randomly turn off 50% of neurons.\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Last layer, remember its binary so we use sigmoid\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3eb0a64534b5445cc437f049ee8f0b4de335c719ef5a3378c563bfc513fc2947"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
